{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hse-proga-hw6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "odGDElcc-bI8"
      },
      "source": [
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shq-I971-fkQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model as tfModel\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, Bidirectional, TimeDistributed, InputLayer\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, Conv2D, Input, concatenate, SpatialDropout1D, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import optimizers\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQb4Dcjtcwxk"
      },
      "source": [
        "col_names = ['id', 'tdate', 'tmane', 'ttext', 'ttype', 'trep', 'tfav', 'tstcount', 'tfol', 'tfrien', 'listcount']\n",
        "pos = pd.read_csv('positive.csv', sep=';', names=col_names, index_col=False)\n",
        "neg = pd.read_csv('negative.csv', sep=';', names=col_names, index_col=False)"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbml6ErTA8nM"
      },
      "source": [
        "neg['ttype'] = [0 for i in range(len(neg))]"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjFhdb8L9ueS"
      },
      "source": [
        "pos = pos[:500]\n",
        "neg = neg[:500]"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcGaj288h7lF"
      },
      "source": [
        "corpus = pd.concat([pos, neg])\n",
        "corpus = corpus.sample(frac=1).reset_index(drop=True)\n",
        "corpus = corpus[[\"ttext\", \"ttype\"]]"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXTL0dCxcZ5U"
      },
      "source": [
        "## 0. Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIioeuL9cs6V",
        "outputId": "0c156405-1a86-4301-8c4d-8d2fd2ec7a91"
      },
      "source": [
        "!pip install ufal.udpipe"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ufal.udpipe in /usr/local/lib/python3.6/dist-packages (1.2.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf1IMKWIfJL0",
        "outputId": "3eea39a1-62d4-409a-9f12-627217d886b9"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import wget\n",
        "import re\n",
        "from ufal.udpipe import Model, Pipeline\n",
        "\n",
        "\"\"\"\n",
        "Этот скрипт принимает на вход необработанный русский текст \n",
        "(одно предложение на строку или один абзац на строку).\n",
        "Он токенизируется, лемматизируется и размечается по частям речи с использованием UDPipe.\n",
        "На выход подаётся последовательность разделенных пробелами лемм с частями речи \n",
        "(\"зеленый_NOUN трамвай_NOUN\").\n",
        "Их можно непосредственно использовать в моделях с RusVectōrēs (https://rusvectores.org).\n",
        "Примеры запуска:\n",
        "echo 'Мама мыла раму.' | python3 rus_preprocessing_udpipe.py\n",
        "zcat large_corpus.txt.gz | python3 rus_preprocessing_udpipe.py | gzip > processed_corpus.txt.gz\n",
        "\"\"\"\n",
        "\n",
        "def num_replace(word):\n",
        "    newtoken = \"x\" * len(word)\n",
        "    return newtoken\n",
        "\n",
        "\n",
        "def clean_token(token, misc):\n",
        "    \"\"\"\n",
        "    :param token:  токен (строка)\n",
        "    :param misc:  содержимое поля \"MISC\" в CONLLU (строка)\n",
        "    :return: очищенный токен (строка)\n",
        "    \"\"\"\n",
        "    out_token = token.strip().replace(\" \", \"\")\n",
        "    if token == \"Файл\" and \"SpaceAfter=No\" in misc:\n",
        "        return None\n",
        "    return out_token\n",
        "\n",
        "\n",
        "def clean_lemma(lemma, pos):\n",
        "    \"\"\"\n",
        "    :param lemma: лемма (строка)\n",
        "    :param pos: часть речи (строка)\n",
        "    :return: очищенная лемма (строка)\n",
        "    \"\"\"\n",
        "    out_lemma = lemma.strip().replace(\" \", \"\").replace(\"_\", \"\").lower()\n",
        "    if \"|\" in out_lemma or out_lemma.endswith(\".jpg\") or out_lemma.endswith(\".png\"):\n",
        "        return None\n",
        "    if pos != \"PUNCT\":\n",
        "        if out_lemma.startswith(\"«\") or out_lemma.startswith(\"»\"):\n",
        "            out_lemma = \"\".join(out_lemma[1:])\n",
        "        if out_lemma.endswith(\"«\") or out_lemma.endswith(\"»\"):\n",
        "            out_lemma = \"\".join(out_lemma[:-1])\n",
        "        if (\n",
        "            out_lemma.endswith(\"!\")\n",
        "            or out_lemma.endswith(\"?\")\n",
        "            or out_lemma.endswith(\",\")\n",
        "            or out_lemma.endswith(\".\")\n",
        "        ):\n",
        "            out_lemma = \"\".join(out_lemma[:-1])\n",
        "    return out_lemma\n",
        "\n",
        "\n",
        "def list_replace(search, replacement, text):\n",
        "    search = [el for el in search if el in text]\n",
        "    for c in search:\n",
        "        text = text.replace(c, replacement)\n",
        "    return text\n",
        "\n",
        "\n",
        "def unify_sym(text):  # принимает строку в юникоде\n",
        "    text = list_replace(\n",
        "        \"\\u00AB\\u00BB\\u2039\\u203A\\u201E\\u201A\\u201C\\u201F\\u2018\\u201B\\u201D\\u2019\",\n",
        "        \"\\u0022\",\n",
        "        text,\n",
        "    )\n",
        "\n",
        "    text = list_replace(\n",
        "        \"\\u2012\\u2013\\u2014\\u2015\\u203E\\u0305\\u00AF\", \"\\u2003\\u002D\\u002D\\u2003\", text\n",
        "    )\n",
        "\n",
        "    text = list_replace(\"\\u2010\\u2011\", \"\\u002D\", text)\n",
        "\n",
        "    text = list_replace(\n",
        "        \"\\u2000\\u2001\\u2002\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u200B\\u202F\\u205F\\u2060\\u3000\",\n",
        "        \"\\u2002\",\n",
        "        text,\n",
        "    )\n",
        "\n",
        "    text = re.sub(\"\\u2003\\u2003\", \"\\u2003\", text)\n",
        "    text = re.sub(\"\\t\\t\", \"\\t\", text)\n",
        "\n",
        "    text = list_replace(\n",
        "        \"\\u02CC\\u0307\\u0323\\u2022\\u2023\\u2043\\u204C\\u204D\\u2219\\u25E6\\u00B7\\u00D7\\u22C5\\u2219\\u2062\",\n",
        "        \".\",\n",
        "        text,\n",
        "    )\n",
        "\n",
        "    text = list_replace(\"\\u2217\", \"\\u002A\", text)\n",
        "\n",
        "    text = list_replace(\"…\", \"...\", text)\n",
        "\n",
        "    text = list_replace(\"\\u2241\\u224B\\u2E2F\\u0483\", \"\\u223D\", text)\n",
        "\n",
        "    text = list_replace(\"\\u00C4\", \"A\", text)  # латинская\n",
        "    text = list_replace(\"\\u00E4\", \"a\", text)\n",
        "    text = list_replace(\"\\u00CB\", \"E\", text)\n",
        "    text = list_replace(\"\\u00EB\", \"e\", text)\n",
        "    text = list_replace(\"\\u1E26\", \"H\", text)\n",
        "    text = list_replace(\"\\u1E27\", \"h\", text)\n",
        "    text = list_replace(\"\\u00CF\", \"I\", text)\n",
        "    text = list_replace(\"\\u00EF\", \"i\", text)\n",
        "    text = list_replace(\"\\u00D6\", \"O\", text)\n",
        "    text = list_replace(\"\\u00F6\", \"o\", text)\n",
        "    text = list_replace(\"\\u00DC\", \"U\", text)\n",
        "    text = list_replace(\"\\u00FC\", \"u\", text)\n",
        "    text = list_replace(\"\\u0178\", \"Y\", text)\n",
        "    text = list_replace(\"\\u00FF\", \"y\", text)\n",
        "    text = list_replace(\"\\u00DF\", \"s\", text)\n",
        "    text = list_replace(\"\\u1E9E\", \"S\", text)\n",
        "\n",
        "    currencies = list(\n",
        "        \"\\u20BD\\u0024\\u00A3\\u20A4\\u20AC\\u20AA\\u2133\\u20BE\\u00A2\\u058F\\u0BF9\\u20BC\\u20A1\\u20A0\\u20B4\\u20A7\\u20B0\\u20BF\\u20A3\\u060B\\u0E3F\\u20A9\\u20B4\\u20B2\\u0192\\u20AB\\u00A5\\u20AD\\u20A1\\u20BA\\u20A6\\u20B1\\uFDFC\\u17DB\\u20B9\\u20A8\\u20B5\\u09F3\\u20B8\\u20AE\\u0192\"\n",
        "    )\n",
        "\n",
        "    alphabet = list(\n",
        "        '\\t\\n\\r абвгдеёзжийклмнопрстуфхцчшщьыъэюяАБВГДЕЁЗЖИЙКЛМНОПРСТУФХЦЧШЩЬЫЪЭЮЯ,.[]{}()=+-−*&^%$#@!?~;:0123456789§/\\|\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ '\n",
        "    )\n",
        "\n",
        "    alphabet.append(\"'\")\n",
        "\n",
        "    allowed = set(currencies + alphabet)\n",
        "\n",
        "    cleaned_text = [sym for sym in text if sym in allowed]\n",
        "    cleaned_text = \"\".join(cleaned_text)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "def process(pipeline, text=\"Строка\", keep_pos=True, keep_punct=False):\n",
        "    # Если частеречные тэги не нужны (например, их нет в модели), выставьте pos=False\n",
        "    # в этом случае на выход будут поданы только леммы\n",
        "    # По умолчанию знаки пунктуации вырезаются. Чтобы сохранить их, выставьте punct=True\n",
        "\n",
        "    entities = {\"PROPN\"}\n",
        "    named = False\n",
        "    memory = []\n",
        "    mem_case = None\n",
        "    mem_number = None\n",
        "    tagged_propn = []\n",
        "\n",
        "    # обрабатываем текст, получаем результат в формате conllu:\n",
        "    processed = pipeline.process(text)\n",
        "\n",
        "    # пропускаем строки со служебной информацией:\n",
        "    content = [line for line in processed.split(\"\\n\") if not line.startswith(\"#\")]\n",
        "\n",
        "    # извлекаем из обработанного текста леммы, тэги и морфологические характеристики\n",
        "    tagged = [w.split(\"\\t\") for w in content if w]\n",
        "\n",
        "    for t in tagged:\n",
        "        if len(t) != 10:\n",
        "            continue\n",
        "        (word_id, token, lemma, pos, xpos, feats, head, deprel, deps, misc) = t\n",
        "        token = clean_token(token, misc)\n",
        "        lemma = clean_lemma(lemma, pos)\n",
        "        if not lemma or not token:\n",
        "            continue\n",
        "        if pos in entities:\n",
        "            if \"|\" not in feats:\n",
        "                tagged_propn.append(\"%s_%s\" % (lemma, pos))\n",
        "                continue\n",
        "            morph = {el.split(\"=\")[0]: el.split(\"=\")[1] for el in feats.split(\"|\")}\n",
        "            if \"Case\" not in morph or \"Number\" not in morph:\n",
        "                tagged_propn.append(\"%s_%s\" % (lemma, pos))\n",
        "                continue\n",
        "            if not named:\n",
        "                named = True\n",
        "                mem_case = morph[\"Case\"]\n",
        "                mem_number = morph[\"Number\"]\n",
        "            if morph[\"Case\"] == mem_case and morph[\"Number\"] == mem_number:\n",
        "                memory.append(lemma)\n",
        "                if \"SpacesAfter=\\\\n\" in misc or \"SpacesAfter=\\s\\\\n\" in misc:\n",
        "                    named = False\n",
        "                    past_lemma = \"::\".join(memory)\n",
        "                    memory = []\n",
        "                    tagged_propn.append(past_lemma + \"_PROPN\")\n",
        "            else:\n",
        "                named = False\n",
        "                past_lemma = \"::\".join(memory)\n",
        "                memory = []\n",
        "                tagged_propn.append(past_lemma + \"_PROPN\")\n",
        "                tagged_propn.append(\"%s_%s\" % (lemma, pos))\n",
        "        else:\n",
        "            if not named:\n",
        "                if (\n",
        "                    pos == \"NUM\" and token.isdigit()\n",
        "                ):  # Заменяем числа на xxxxx той же длины\n",
        "                    lemma = num_replace(token)\n",
        "                tagged_propn.append(\"%s_%s\" % (lemma, pos))\n",
        "            else:\n",
        "                named = False\n",
        "                past_lemma = \"::\".join(memory)\n",
        "                memory = []\n",
        "                tagged_propn.append(past_lemma + \"_PROPN\")\n",
        "                tagged_propn.append(\"%s_%s\" % (lemma, pos))\n",
        "\n",
        "    if not keep_punct:\n",
        "        tagged_propn = [word for word in tagged_propn if word.split(\"_\")[1] != \"PUNCT\"]\n",
        "    if not keep_pos:\n",
        "        tagged_propn = [word.split(\"_\")[0] for word in tagged_propn]\n",
        "    return tagged_propn\n",
        "\n",
        "\n",
        "# URL of the UDPipe model\n",
        "udpipe_model_url = \"https://rusvectores.org/static/models/udpipe_syntagrus.model\"\n",
        "udpipe_filename = udpipe_model_url.split(\"/\")[-1]\n",
        "\n",
        "if not os.path.isfile(udpipe_filename):\n",
        "    print(\"UDPipe model not found. Downloading...\", file=sys.stderr)\n",
        "    wget.download(udpipe_model_url)\n",
        "\n",
        "print(\"\\nLoading the model...\", file=sys.stderr)\n",
        "model = Model.load(udpipe_filename)\n",
        "process_pipeline = Pipeline(\n",
        "    model, \"tokenize\", Pipeline.DEFAULT, Pipeline.DEFAULT, \"conllu\"\n",
        ")\n",
        "\n",
        "print(\"Processing input...\", file=sys.stderr)\n",
        "for input_line in sys.stdin:\n",
        "    res = unify_sym(input_line.strip())\n",
        "    output = process(process_pipeline, text=res)\n",
        "    print(\" \".join(output))"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading the model...\n",
            "Processing input...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_ryzw25gjow",
        "outputId": "d0ebbad5-4b5a-4e22-a6be-efcb117bc5e1"
      },
      "source": [
        "output = process(process_pipeline, text=corpus[\"ttext\"][1])\n",
        "#print(\" \".join(output))\n",
        "print(output)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rt_PROPN', '@radughniykot_X', 'вечеринка_NOUN', 'привет_NOUN', 'о_ADP', 'хотя_SCONJ', 'ты_PRON', 'насрать_VERB', 'x_NUM', 'xxx_NUM']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQosDutwjDpi"
      },
      "source": [
        "corpus[\"ttext_pos\"] = [\" \".join(process(process_pipeline, text=twit)) for twit in corpus[\"ttext\"]]"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RbUkh78lrzu"
      },
      "source": [
        "corpus[\"ttext_processed\"] = [\" \".join(process(process_pipeline, keep_pos=False, text=twit)) for twit in corpus[\"ttext\"]]"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g23WQZW01dFq"
      },
      "source": [
        "#1. Простая модель, embedding слой обучается внутри модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JPPCxofiyuU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = np.array(list(corpus['ttype']))\n",
        "X = np.array(list(corpus[\"ttext_processed\"]))\n",
        "twit_train,twit_test,tag_train,tag_test = train_test_split(X,y,test_size=0.2)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQoi2JwXnOFa"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "vocab = Counter()\n",
        "for sent in twit_train:\n",
        "    sent = [word.lower() for word in sent.split()]\n",
        "    vocab.update(sent)"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAr_O4Dnn0Bj"
      },
      "source": [
        "filtered_vocab = {word for word in vocab if vocab[word] > 5}"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcdAprntn8_N",
        "outputId": "fbd510dd-52e2-43a0-f792-a339ec6b7eb8"
      },
      "source": [
        "len(filtered_vocab)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jeYJbdGoMbR"
      },
      "source": [
        "word2id = {word:i + 2 for i,word in enumerate(filtered_vocab)}\n",
        "word2id['pad'] = 0\n",
        "word2id['unk'] = 1  \n",
        "\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9nBgJlCodxX"
      },
      "source": [
        "chars = set([letter for word in filtered_vocab for letter in word])\n",
        "n_chars = len(chars)\n",
        "char2id = {c: i + 2 for i, c in enumerate(chars)}\n",
        "char2id[\"pad\"] = 0\n",
        "char2id[\"unk\"] = 1\n",
        "\n",
        "id2char = {i:char for char, i in char2id.items()}"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa-Ef5uLom7X",
        "outputId": "2148e2a1-cc5e-4923-afed-069a6a8a6b99"
      },
      "source": [
        "char_max_len = max(len(x) for x in filtered_vocab)\n",
        "print(\"максимальная длина слова:\", char_max_len)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "максимальная длина слова: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfQ35pqJouW_"
      },
      "source": [
        "def data2ints(data, smth2id):\n",
        "  int_data = []\n",
        "  for seq in data:\n",
        "      int_seq = []\n",
        "      for i in seq:\n",
        "        int_seq.append(smth2id.get(i.lower(), 1))\n",
        "  \n",
        "      int_data.append(int_seq)\n",
        "  return int_data"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvLHxD4doyOL"
      },
      "source": [
        "X_train_ids, X_test_ids = data2ints(twit_train, word2id), data2ints(twit_test, word2id)\n",
        "y_train_ids, y_test_ids = list(tag_train), list(tag_test)"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CZpY7KlpO03",
        "outputId": "0d2b651b-b369-47e9-8527-f053a38655c4"
      },
      "source": [
        "sent_max_len = max(len(x) for x in X_train_ids)\n",
        "print(\"максимальная длина твита:\", sent_max_len)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "максимальная длина твита: 144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAEzSKOcpdsu"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train, X_test = pad_sequences(X_train_ids, maxlen=sent_max_len, padding='post'), pad_sequences(X_test_ids, maxlen=sent_max_len, padding='post')"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfr2GbjaNF_8"
      },
      "source": [
        "tag_test = np.array(list(tag_test))\n",
        "tag_train = np.array(list(tag_train))"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P11BFBSVpxqB"
      },
      "source": [
        "def make_X_char(sentences):\n",
        "  X_char = []\n",
        "  for sentence in sentences:\n",
        "      sent_seq = []\n",
        "      for i in range(sent_max_len):\n",
        "          word_seq = []\n",
        "          for j in range(char_max_len):\n",
        "              try:\n",
        "                  word_seq.append(char2id[sentence[i][j].lower()])\n",
        "              except:\n",
        "                  word_seq.append(char2id[\"pad\"])\n",
        "          sent_seq.append(word_seq)\n",
        "      X_char.append(np.array(sent_seq))\n",
        "  return np.array(X_char)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRGUJz22p0ju"
      },
      "source": [
        "X_char_train, X_char_test = make_X_char(twit_train), make_X_char(twit_test)"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6ADiGucQC07"
      },
      "source": [
        "tag_train, tag_test = to_categorical(tag_train, num_classes=2), to_categorical(tag_test, num_classes=2)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCHPZ1XRSCdR",
        "outputId": "4a0d8829-849a-409c-c4f3-03ce52c37590"
      },
      "source": [
        "len(word2id)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEG6YakZrTuz"
      },
      "source": [
        "word_in = Input(shape=(sent_max_len,))\n",
        "emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len)(word_in)\n",
        "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.2))(emb_word)\n",
        "lstm2 = Bidirectional(LSTM(units=128, recurrent_dropout=0.2))(emb_word)\n",
        "out = Dense(2, activation=\"softmax\")(lstm2)\n",
        "\n",
        "\n",
        "model = tfModel(inputs= word_in, outputs=out)\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()])"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCU73woz7otY",
        "outputId": "31567c28-d3b2-43bb-c10d-391c0b4d6a04"
      },
      "source": [
        "emb_word"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 144, 20) dtype=float32 (created by layer 'embedding_20')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8fAWfR979vm",
        "outputId": "2d0abbac-0b97-45d1-809d-65c84d28ca9c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        [(None, 144)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_20 (Embedding)     (None, 144, 20)           3880      \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, 256)               152576    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 156,970\n",
            "Trainable params: 156,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEYC4Yw28MON"
      },
      "source": [
        "model.fit(X_train, tag_train, validation_data=(X_test, tag_test), batch_size=128, epochs=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SKDhpxi1r9N"
      },
      "source": [
        "#2. Простая модель, подгружаются обученные эмбеддинги для русского языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PstW_8F7b3HE"
      },
      "source": [
        "pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkwNzi_BzF2v"
      },
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec as w2v\n",
        "import wget\n",
        "\n",
        "#>>> model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "#>>> model.save(\"word2vec.model\")"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_QmaTCmbuk3"
      },
      "source": [
        "import zipfile\n",
        "model_url = 'http://vectors.nlpl.eu/repository/11/180.zip'\n",
        "m = wget.download(model_url)\n",
        "model_file = model_url.split('/')[-1]\n",
        "with zipfile.ZipFile(model_file, 'r') as archive:\n",
        "    stream = archive.open('model.bin')\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UctJN-5XvMcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9521e0c-212f-4007-dbb6-3325bda32d5d"
      },
      "source": [
        "model.wv.get_keras_embedding(train_embeddings=False)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f4f13c3d518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfItuM1or0yo"
      },
      "source": [
        "y = np.array(list(corpus['ttype']))\n",
        "X = np.array(list(corpus[\"ttext_pos\"]))\n",
        "twit_train,twit_test,tag_train,tag_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "vocab = Counter()\n",
        "for sent in twit_train:\n",
        "    sent = [word for word in sent.split()]\n",
        "    vocab.update(sent)\n",
        "\n",
        "filtered_vocab = {word for word in vocab if vocab[word] > 5}"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItdU5Uyztxgc",
        "outputId": "3c8edf2e-518d-4bce-d9f8-17c5d4c8e721"
      },
      "source": [
        "model['песня_NOUN'].shape"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1FJ5IRKyuUi",
        "outputId": "4742a0d9-a316-4721-f239-6f76402e96b7"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "\n",
        "#w2v = gensim.models.Word2Vec.load(\"models/w2v.model\")\n",
        "vocab = model.wv.vocab    \n",
        "t = Tokenizer()\n",
        "\n",
        "filtered_vocab_list = list(filtered_vocab)\n",
        "\n",
        "vocab_size = len(filtered_vocab_list) + 1\n",
        "t.fit_on_texts(filtered_vocab_list)\n",
        "\n",
        "def get_weight_matrix():\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, model.vector_size))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for i in range(len(filtered_vocab)):\n",
        "        try:\n",
        "            weight_matrix[i + 1] = model[filtered_vocab_list[i]]\n",
        "        except:\n",
        "            continue\n",
        "    return weight_matrix\n",
        "\n",
        "weight_matrix = get_weight_matrix()"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTtwoxIPtAtA",
        "outputId": "925bbe58-ef22-4419-b44d-574c61d91389"
      },
      "source": [
        "model.get_keras_embedding(train_embeddings=False)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f4f0686f898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZr4Gfw_wQqd",
        "outputId": "f69b9b84-1403-46e3-ba3a-1d82db77b993"
      },
      "source": [
        "emb_word"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f4f04a78240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1TLNwgvuvwn"
      },
      "source": [
        "word_in = Input(shape=(sent_max_len,))\n",
        "\n",
        "#emb_word = model.get_keras_embedding(train_embeddings=False)(word_in)\n",
        "emb_word = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300, trainable=False, weights=[weight_matrix])(word_in)\n",
        "#emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len)(word_in)\n",
        "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.2))(emb_word)\n",
        "lstm2 = Bidirectional(LSTM(units=128, recurrent_dropout=0.2))(emb_word)\n",
        "out = Dense(2, activation=\"softmax\")(lstm2)\n",
        "\n",
        "\n",
        "model2 = tfModel(inputs= word_in, outputs=out)\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model2.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()])"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZokUbzKw9Wp"
      },
      "source": [
        "tag_train\n",
        "tag_train, tag_test = to_categorical(tag_train, num_classes=2), to_categorical(tag_test, num_classes=2)"
      ],
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HauY-e5sxfDs"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0q7kVi4u_q1",
        "outputId": "ed684ce5-07e2-4b94-b974-144804db4bdb"
      },
      "source": [
        "model2.fit(X_train, tag_train, validation_data=(X_test, tag_test), batch_size=128, epochs=30, verbose=1)"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 32s 4s/step - loss: 0.7050 - precision_20: 0.5013 - recall_20: 0.5013 - accuracy: 0.0000e+00 - val_loss: 0.6927 - val_precision_20: 0.5050 - val_recall_20: 0.5050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6894 - precision_20: 0.5325 - recall_20: 0.5325 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_precision_20: 0.5400 - val_recall_20: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6817 - precision_20: 0.5600 - recall_20: 0.5600 - accuracy: 0.0000e+00 - val_loss: 0.6914 - val_precision_20: 0.4800 - val_recall_20: 0.4800 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 31s 5s/step - loss: 0.6772 - precision_20: 0.5738 - recall_20: 0.5738 - accuracy: 0.0000e+00 - val_loss: 0.6924 - val_precision_20: 0.4950 - val_recall_20: 0.4950 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 31s 5s/step - loss: 0.6720 - precision_20: 0.5688 - recall_20: 0.5688 - accuracy: 0.0000e+00 - val_loss: 0.6961 - val_precision_20: 0.4900 - val_recall_20: 0.4900 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6677 - precision_20: 0.5850 - recall_20: 0.5850 - accuracy: 0.0000e+00 - val_loss: 0.6982 - val_precision_20: 0.5050 - val_recall_20: 0.5050 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6602 - precision_20: 0.5913 - recall_20: 0.5913 - accuracy: 0.0000e+00 - val_loss: 0.7015 - val_precision_20: 0.5100 - val_recall_20: 0.5100 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 30s 4s/step - loss: 0.6595 - precision_20: 0.5888 - recall_20: 0.5888 - accuracy: 0.0000e+00 - val_loss: 0.7027 - val_precision_20: 0.5300 - val_recall_20: 0.5300 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6487 - precision_20: 0.5962 - recall_20: 0.5962 - accuracy: 0.0000e+00 - val_loss: 0.7094 - val_precision_20: 0.5050 - val_recall_20: 0.5050 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6397 - precision_20: 0.6250 - recall_20: 0.6250 - accuracy: 0.0000e+00 - val_loss: 0.7262 - val_precision_20: 0.5000 - val_recall_20: 0.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.6367 - precision_20: 0.6225 - recall_20: 0.6225 - accuracy: 0.0000e+00 - val_loss: 0.7171 - val_precision_20: 0.4950 - val_recall_20: 0.4950 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 31s 5s/step - loss: 0.6359 - precision_20: 0.6300 - recall_20: 0.6300 - accuracy: 0.0000e+00 - val_loss: 0.7179 - val_precision_20: 0.5350 - val_recall_20: 0.5350 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.6288 - precision_20: 0.6475 - recall_20: 0.6475 - accuracy: 0.0000e+00 - val_loss: 0.7087 - val_precision_20: 0.5600 - val_recall_20: 0.5600 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.6221 - precision_20: 0.6488 - recall_20: 0.6488 - accuracy: 0.0000e+00 - val_loss: 0.7209 - val_precision_20: 0.5900 - val_recall_20: 0.5900 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.6137 - precision_20: 0.6562 - recall_20: 0.6562 - accuracy: 0.0000e+00 - val_loss: 0.7348 - val_precision_20: 0.5150 - val_recall_20: 0.5150 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.6018 - precision_20: 0.6900 - recall_20: 0.6900 - accuracy: 0.0000e+00 - val_loss: 0.7334 - val_precision_20: 0.5200 - val_recall_20: 0.5200 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.5970 - precision_20: 0.6862 - recall_20: 0.6862 - accuracy: 0.0000e+00 - val_loss: 0.7469 - val_precision_20: 0.5100 - val_recall_20: 0.5100 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.6130 - precision_20: 0.6850 - recall_20: 0.6850 - accuracy: 0.0000e+00 - val_loss: 0.7489 - val_precision_20: 0.5050 - val_recall_20: 0.5050 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.5717 - precision_20: 0.7088 - recall_20: 0.7088 - accuracy: 0.0000e+00 - val_loss: 0.7457 - val_precision_20: 0.5600 - val_recall_20: 0.5600 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.5652 - precision_20: 0.7075 - recall_20: 0.7075 - accuracy: 0.0000e+00 - val_loss: 0.7389 - val_precision_20: 0.5550 - val_recall_20: 0.5550 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.5479 - precision_20: 0.7287 - recall_20: 0.7287 - accuracy: 0.0000e+00 - val_loss: 0.7740 - val_precision_20: 0.5300 - val_recall_20: 0.5300 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.5449 - precision_20: 0.7300 - recall_20: 0.7300 - accuracy: 0.0000e+00 - val_loss: 0.7875 - val_precision_20: 0.5400 - val_recall_20: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 31s 5s/step - loss: 0.5304 - precision_20: 0.7412 - recall_20: 0.7412 - accuracy: 0.0000e+00 - val_loss: 0.7639 - val_precision_20: 0.5500 - val_recall_20: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 33s 5s/step - loss: 0.5269 - precision_20: 0.7362 - recall_20: 0.7362 - accuracy: 0.0000e+00 - val_loss: 0.7368 - val_precision_20: 0.5800 - val_recall_20: 0.5800 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.5181 - precision_20: 0.7500 - recall_20: 0.7500 - accuracy: 0.0000e+00 - val_loss: 0.7719 - val_precision_20: 0.5450 - val_recall_20: 0.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.4962 - precision_20: 0.7638 - recall_20: 0.7638 - accuracy: 0.0000e+00 - val_loss: 0.8093 - val_precision_20: 0.5600 - val_recall_20: 0.5600 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.4936 - precision_20: 0.7638 - recall_20: 0.7638 - accuracy: 0.0000e+00 - val_loss: 0.8161 - val_precision_20: 0.5550 - val_recall_20: 0.5550 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.4929 - precision_20: 0.7650 - recall_20: 0.7650 - accuracy: 0.0000e+00 - val_loss: 0.8031 - val_precision_20: 0.5400 - val_recall_20: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.4645 - precision_20: 0.7812 - recall_20: 0.7812 - accuracy: 0.0000e+00 - val_loss: 0.8014 - val_precision_20: 0.5500 - val_recall_20: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.4576 - precision_20: 0.7987 - recall_20: 0.7987 - accuracy: 0.0000e+00 - val_loss: 0.8266 - val_precision_20: 0.5450 - val_recall_20: 0.5450 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f03ae70f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ0kmPdy1zYh"
      },
      "source": [
        "#3. Простая модель, fasttext эмбеддинги обучаются на всем корпусе с нуля"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "942DtBPf16gb"
      },
      "source": [
        "from gensim.models import FastText\n",
        "#model = FastText(size=4, window=3, min_count=1, sentences=twit_train, epochs=10)\n",
        "ft = gensim.models.FastText(twit_train, size=20, iter=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0YLWYqU4bLA"
      },
      "source": [
        "max_len = 140\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True)\n",
        "tokenizer.fit_on_texts(twit_train)\n",
        "\n",
        "sequence_docs = tokenizer.texts_to_sequences(twit_train)\n",
        "sequence_docs = tf.keras.preprocessing.sequence.pad_sequences(sequence_docs, maxlen=max_len)\n",
        "\n",
        "# extract fasttext learned embedding and put them in a numpy array\n",
        "\n",
        "embedding_matrix_ft = np.random.random((len(tokenizer.word_index) + 1, ft.vector_size))\n",
        "\n",
        "pas = 0\n",
        "for word,i in tokenizer.word_index.items():\n",
        "    \n",
        "    try:\n",
        "        embedding_matrix_ft[i] = ft.wv[word]\n",
        "    except:\n",
        "        pas+=1\n",
        "\n",
        "# define a keras model and load the pretrained fasttext weights matrix\n",
        "\n",
        "inp = Input(shape=(max_len,))\n",
        "emb = Embedding(len(tokenizer.word_index) + 1, ft.vector_size, \n",
        "                weights=[embedding_matrix_ft], trainable=False)(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_7s7bzN7RSh",
        "outputId": "3edf772e-a23f-4570-cfb8-828726448898"
      },
      "source": [
        "embedding_matrix_ft.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFYKTDaD6-OO",
        "outputId": "2c3241f0-1663-4570-9374-0f1448f46e86"
      },
      "source": [
        "emb_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 140, 20) dtype=float32 (created by layer 'embedding_12')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdS3HRo32b0c"
      },
      "source": [
        "word_in = Input(shape=(sent_max_len, ))\n",
        "#emb_word = Embedding(input_dim=len(word2id), output_dim=20, mask_zero=True)(word_in)\n",
        "emb_word = Embedding(len(tokenizer.word_index) + 1, ft.vector_size, \n",
        "                weights=[embedding_matrix_ft], trainable=False)(word_in)\n",
        "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.2))(emb_word)\n",
        "lstm2 = Bidirectional(LSTM(units=128, recurrent_dropout=0.2))(emb_word)\n",
        "out = Dense(1, activation=\"softmax\")(lstm2)\n",
        "\n",
        "model = Model(inputs= word_in, outputs=out)\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar9vtyfv8-qN"
      },
      "source": [
        "unseen_docs = twit_test\n",
        "unseen_docs = [d.lower().split() for d in unseen_docs]\n",
        "\n",
        "sequence_unseen_docs = tokenizer.texts_to_sequences(unseen_docs)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(sequence_unseen_docs, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OrCD2Y475xi",
        "outputId": "53e54290-5a63-4d22-9f50-d8624c279eb1"
      },
      "source": [
        "model.fit(sequence_docs, tag_train, validation_data=(X_test, tag_test), batch_size=128, epochs=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 7s 2s/step - loss: 0.6946 - precision_4: 0.4865 - recall_4: 1.0000 - accuracy: 0.4865 - val_loss: 0.7035 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 2s 703ms/step - loss: 0.6947 - precision_4: 0.4969 - recall_4: 1.0000 - accuracy: 0.4969 - val_loss: 0.6870 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 2s 679ms/step - loss: 0.6884 - precision_4: 0.4865 - recall_4: 1.0000 - accuracy: 0.4865 - val_loss: 0.7098 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 2s 713ms/step - loss: 0.6836 - precision_4: 0.4839 - recall_4: 1.0000 - accuracy: 0.4839 - val_loss: 0.7237 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 2s 701ms/step - loss: 0.6822 - precision_4: 0.4813 - recall_4: 1.0000 - accuracy: 0.4813 - val_loss: 0.7122 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 2s 703ms/step - loss: 0.6776 - precision_4: 0.4865 - recall_4: 1.0000 - accuracy: 0.4865 - val_loss: 0.6989 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 2s 684ms/step - loss: 0.6773 - precision_4: 0.4917 - recall_4: 1.0000 - accuracy: 0.4917 - val_loss: 0.7054 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 2s 700ms/step - loss: 0.6728 - precision_4: 0.4865 - recall_4: 1.0000 - accuracy: 0.4865 - val_loss: 0.7403 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 2s 710ms/step - loss: 0.6657 - precision_4: 0.4734 - recall_4: 1.0000 - accuracy: 0.4734 - val_loss: 0.7603 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 2s 693ms/step - loss: 0.6583 - precision_4: 0.4813 - recall_4: 1.0000 - accuracy: 0.4813 - val_loss: 0.7365 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 2s 693ms/step - loss: 0.6635 - precision_4: 0.4839 - recall_4: 1.0000 - accuracy: 0.4839 - val_loss: 0.7317 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 2s 707ms/step - loss: 0.6626 - precision_4: 0.4891 - recall_4: 1.0000 - accuracy: 0.4891 - val_loss: 0.7697 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 2s 696ms/step - loss: 0.6476 - precision_4: 0.4969 - recall_4: 1.0000 - accuracy: 0.4969 - val_loss: 0.8614 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 2s 688ms/step - loss: 0.6546 - precision_4: 0.4839 - recall_4: 1.0000 - accuracy: 0.4839 - val_loss: 0.9120 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 2s 995ms/step - loss: 0.6484 - precision_4: 0.4813 - recall_4: 1.0000 - accuracy: 0.4813 - val_loss: 0.8473 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 2s 719ms/step - loss: 0.6429 - precision_4: 0.4865 - recall_4: 1.0000 - accuracy: 0.4865 - val_loss: 0.7810 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 2s 701ms/step - loss: 0.6411 - precision_4: 0.4813 - recall_4: 1.0000 - accuracy: 0.4813 - val_loss: 0.7711 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 2s 710ms/step - loss: 0.6457 - precision_4: 0.4969 - recall_4: 1.0000 - accuracy: 0.4969 - val_loss: 0.8007 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 2s 697ms/step - loss: 0.6366 - precision_4: 0.4839 - recall_4: 1.0000 - accuracy: 0.4839 - val_loss: 0.8635 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 2s 708ms/step - loss: 0.6323 - precision_4: 0.4839 - recall_4: 1.0000 - accuracy: 0.4839 - val_loss: 0.9147 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 2s 702ms/step - loss: 0.6302 - precision_4: 0.4786 - recall_4: 1.0000 - accuracy: 0.4786 - val_loss: 0.9190 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 2s 699ms/step - loss: 0.6238 - precision_4: 0.4891 - recall_4: 1.0000 - accuracy: 0.4891 - val_loss: 0.9017 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 2s 694ms/step - loss: 0.6150 - precision_4: 0.4891 - recall_4: 1.0000 - accuracy: 0.4891 - val_loss: 0.9317 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 2s 693ms/step - loss: 0.6051 - precision_4: 0.4943 - recall_4: 1.0000 - accuracy: 0.4943 - val_loss: 1.0066 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 2s 703ms/step - loss: 0.6042 - precision_4: 0.4917 - recall_4: 1.0000 - accuracy: 0.4917 - val_loss: 1.0703 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 2s 706ms/step - loss: 0.6184 - precision_4: 0.4969 - recall_4: 1.0000 - accuracy: 0.4969 - val_loss: 1.0650 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 2s 713ms/step - loss: 0.6060 - precision_4: 0.4839 - recall_4: 1.0000 - accuracy: 0.4839 - val_loss: 1.0075 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 2s 695ms/step - loss: 0.5944 - precision_4: 0.4891 - recall_4: 1.0000 - accuracy: 0.4891 - val_loss: 0.9668 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 2s 689ms/step - loss: 0.5932 - precision_4: 0.4813 - recall_4: 1.0000 - accuracy: 0.4813 - val_loss: 0.9904 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 2s 702ms/step - loss: 0.5996 - precision_4: 0.4813 - recall_4: 1.0000 - accuracy: 0.4813 - val_loss: 1.0152 - val_precision_4: 0.5500 - val_recall_4: 1.0000 - val_accuracy: 0.5500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5d82887390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhemGw0O17Ny"
      },
      "source": [
        "#4. Усложненная архитектура с CharCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSd6JJ0D0V44"
      },
      "source": [
        "word_in = Input(shape=(sent_max_len,))\n",
        "\n",
        "#emb_word = model.get_keras_embedding(train_embeddings=False)(word_in)\n",
        "emb_word = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300, trainable=False, weights=[weight_matrix])(word_in)\n",
        "#emb_word = Embedding(input_dim=len(word2id), output_dim=20, input_length=sent_max_len)(word_in)\n",
        "#lstm1 = Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.2))(emb_word)\n",
        "lstm2 = Bidirectional(LSTM(units=128, recurrent_dropout=0.2))(emb_word)\n",
        "out = Dense(2, activation=\"softmax\")(lstm2)\n",
        "\n",
        "\n",
        "model2 = tfModel(inputs= word_in, outputs=out)\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model2.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()])"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vijgGcsf9Zv"
      },
      "source": [
        "# один вход для слов\n",
        "word_in = Input(shape=(sent_max_len))\n",
        "emb_word = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300, trainable=False, weights=[weight_matrix])(word_in)\n",
        "\n",
        "# другой вход для символов\n",
        "char_in = Input(shape=(sent_max_len, char_max_len))\n",
        "emb_char = TimeDistributed(Embedding(input_dim=len(char2id), output_dim=10, input_length=char_max_len))(char_in)\n",
        "# свертка на символах (CharRNN) применяется к каждому слову отдельно\n",
        "char_enc = TimeDistributed(Conv1D(filters=12, kernel_size=3))(emb_char)\n",
        "char_flat = TimeDistributed(Flatten())(char_enc)\n",
        "\n",
        "# LSTM проходится по всей последовательности, на каждом шаге беря эмбеддинг слова по словарю + символьный эмбеддинг слова \n",
        "x = concatenate([emb_word, char_flat])\n",
        "main_lstm = Bidirectional(LSTM(units=128, recurrent_dropout=0.2))(x)\n",
        "\n",
        "out = Dense(2, activation=\"softmax\")(main_lstm)\n",
        "\n",
        "model3 = tfModel(inputs=[char_in, word_in], outputs=out)\n",
        "\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model3.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()])\n"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3R1P4kzJLPi",
        "outputId": "185c9599-5f5c-4d85-db76-bb66f8d402a2"
      },
      "source": [
        "model3.fit([X_char_train, X_train], tag_train, validation_data=([X_char_test, X_test], tag_test), batch_size=128, epochs=30, verbose=1)"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 39s 5s/step - loss: 0.7043 - precision_22: 0.4801 - recall_22: 0.4801 - accuracy: 0.0000e+00 - val_loss: 0.6964 - val_precision_22: 0.5300 - val_recall_22: 0.5300 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6877 - precision_22: 0.5528 - recall_22: 0.5528 - accuracy: 0.0000e+00 - val_loss: 0.6982 - val_precision_22: 0.5400 - val_recall_22: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6825 - precision_22: 0.5426 - recall_22: 0.5426 - accuracy: 0.0000e+00 - val_loss: 0.7052 - val_precision_22: 0.5200 - val_recall_22: 0.5200 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6876 - precision_22: 0.5543 - recall_22: 0.5543 - accuracy: 0.0000e+00 - val_loss: 0.7015 - val_precision_22: 0.5550 - val_recall_22: 0.5550 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6696 - precision_22: 0.5808 - recall_22: 0.5808 - accuracy: 0.0000e+00 - val_loss: 0.7055 - val_precision_22: 0.4750 - val_recall_22: 0.4750 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6630 - precision_22: 0.5567 - recall_22: 0.5567 - accuracy: 0.0000e+00 - val_loss: 0.7060 - val_precision_22: 0.4950 - val_recall_22: 0.4950 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.6571 - precision_22: 0.5744 - recall_22: 0.5744 - accuracy: 0.0000e+00 - val_loss: 0.7072 - val_precision_22: 0.4800 - val_recall_22: 0.4800 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.6485 - precision_22: 0.6088 - recall_22: 0.6088 - accuracy: 0.0000e+00 - val_loss: 0.7044 - val_precision_22: 0.5100 - val_recall_22: 0.5100 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 39s 5s/step - loss: 0.6571 - precision_22: 0.5978 - recall_22: 0.5978 - accuracy: 0.0000e+00 - val_loss: 0.7003 - val_precision_22: 0.5200 - val_recall_22: 0.5200 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6515 - precision_22: 0.5977 - recall_22: 0.5977 - accuracy: 0.0000e+00 - val_loss: 0.7042 - val_precision_22: 0.5000 - val_recall_22: 0.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.6340 - precision_22: 0.6317 - recall_22: 0.6317 - accuracy: 0.0000e+00 - val_loss: 0.7152 - val_precision_22: 0.4900 - val_recall_22: 0.4900 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 39s 5s/step - loss: 0.6293 - precision_22: 0.6536 - recall_22: 0.6536 - accuracy: 0.0000e+00 - val_loss: 0.7244 - val_precision_22: 0.4850 - val_recall_22: 0.4850 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6228 - precision_22: 0.6481 - recall_22: 0.6481 - accuracy: 0.0000e+00 - val_loss: 0.7257 - val_precision_22: 0.5150 - val_recall_22: 0.5150 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6207 - precision_22: 0.6476 - recall_22: 0.6476 - accuracy: 0.0000e+00 - val_loss: 0.7270 - val_precision_22: 0.5200 - val_recall_22: 0.5200 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 39s 6s/step - loss: 0.6151 - precision_22: 0.6756 - recall_22: 0.6756 - accuracy: 0.0000e+00 - val_loss: 0.7191 - val_precision_22: 0.5500 - val_recall_22: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 39s 6s/step - loss: 0.6070 - precision_22: 0.6640 - recall_22: 0.6640 - accuracy: 0.0000e+00 - val_loss: 0.7256 - val_precision_22: 0.5550 - val_recall_22: 0.5550 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 39s 6s/step - loss: 0.5917 - precision_22: 0.6995 - recall_22: 0.6995 - accuracy: 0.0000e+00 - val_loss: 0.7276 - val_precision_22: 0.5650 - val_recall_22: 0.5650 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.5811 - precision_22: 0.7099 - recall_22: 0.7099 - accuracy: 0.0000e+00 - val_loss: 0.7472 - val_precision_22: 0.5300 - val_recall_22: 0.5300 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5624 - precision_22: 0.7011 - recall_22: 0.7011 - accuracy: 0.0000e+00 - val_loss: 0.7610 - val_precision_22: 0.5450 - val_recall_22: 0.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5588 - precision_22: 0.7037 - recall_22: 0.7037 - accuracy: 0.0000e+00 - val_loss: 0.7737 - val_precision_22: 0.5600 - val_recall_22: 0.5600 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5478 - precision_22: 0.7367 - recall_22: 0.7367 - accuracy: 0.0000e+00 - val_loss: 0.7836 - val_precision_22: 0.5400 - val_recall_22: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5470 - precision_22: 0.7249 - recall_22: 0.7249 - accuracy: 0.0000e+00 - val_loss: 0.7491 - val_precision_22: 0.5700 - val_recall_22: 0.5700 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.5152 - precision_22: 0.7511 - recall_22: 0.7511 - accuracy: 0.0000e+00 - val_loss: 0.7337 - val_precision_22: 0.5650 - val_recall_22: 0.5650 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.5098 - precision_22: 0.7687 - recall_22: 0.7687 - accuracy: 0.0000e+00 - val_loss: 0.7455 - val_precision_22: 0.5750 - val_recall_22: 0.5750 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 39s 6s/step - loss: 0.5040 - precision_22: 0.7518 - recall_22: 0.7518 - accuracy: 0.0000e+00 - val_loss: 0.7856 - val_precision_22: 0.5050 - val_recall_22: 0.5050 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4723 - precision_22: 0.7947 - recall_22: 0.7947 - accuracy: 0.0000e+00 - val_loss: 0.7859 - val_precision_22: 0.5150 - val_recall_22: 0.5150 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4545 - precision_22: 0.8036 - recall_22: 0.8036 - accuracy: 0.0000e+00 - val_loss: 0.8110 - val_precision_22: 0.5200 - val_recall_22: 0.5200 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4392 - precision_22: 0.8075 - recall_22: 0.8075 - accuracy: 0.0000e+00 - val_loss: 0.8278 - val_precision_22: 0.5450 - val_recall_22: 0.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4075 - precision_22: 0.8173 - recall_22: 0.8173 - accuracy: 0.0000e+00 - val_loss: 0.8431 - val_precision_22: 0.5250 - val_recall_22: 0.5250 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4051 - precision_22: 0.8212 - recall_22: 0.8212 - accuracy: 0.0000e+00 - val_loss: 0.8293 - val_precision_22: 0.5500 - val_recall_22: 0.5500 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f03e4ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zdZF0zD5pfF"
      },
      "source": [
        "# 5. Выводы и эксперементы с гиперпараметрами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hl9kwfs51hK"
      },
      "source": [
        "На примере простой модели видно, что лучше всего работает тот вариант модели, где мы используем предобученные эмбеддинги для слов. Что логично, по сути мы используем дополнительные данные («знания» предобученных эмбеддингов о языке вне текущего корпуса) и поэтому лучше учимся работать на неизвестных данных. \n",
        "\n",
        "Усложненная модель работает лучше, чем простая – что, в целом, тоже логично. Для сравнения моделей между собой я смотрю на precision и recall (accuracy плохо считается внутри обучения, я не стала это переделвать). В нашем случае, когда модель работает лучше, обе эти метрики выше.\n",
        "\n",
        "Что касается экспериментов с гиперпараметрами, судя по тому, как падает loss, нашей модели ещё далеко до переобучения, и мы можем просто увеличить количество эпох. Действительно, увеличения количество эпох с 30 до 35 даёт заметный прирост в качестве модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWvKeedr5yYl"
      },
      "source": [
        "# один вход для слов\n",
        "word_in = Input(shape=(sent_max_len))\n",
        "emb_word = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300, trainable=False, weights=[weight_matrix])(word_in)\n",
        "\n",
        "# другой вход для символов\n",
        "char_in = Input(shape=(sent_max_len, char_max_len))\n",
        "emb_char = TimeDistributed(Embedding(input_dim=len(char2id), output_dim=10, input_length=char_max_len))(char_in)\n",
        "# свертка на символах (CharRNN) применяется к каждому слову отдельно\n",
        "char_enc = TimeDistributed(Conv1D(filters=12, kernel_size=3))(emb_char)\n",
        "\n",
        "char_flat = TimeDistributed(Flatten())(char_enc)\n",
        "\n",
        "# LSTM проходится по всей последовательности, на каждом шаге беря эмбеддинг слова по словарю + символьный эмбеддинг слова \n",
        "x = concatenate([emb_word, char_flat])\n",
        "main_lstm = Bidirectional(LSTM(units=128, recurrent_dropout=0.2))(x)\n",
        "\n",
        "out = Dense(2, activation=\"softmax\")(main_lstm)\n",
        "\n",
        "model4 = tfModel(inputs=[char_in, word_in], outputs=out)\n",
        "\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model4.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.Accuracy()])\n"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AkjrVoZ7wi2",
        "outputId": "31c9988e-2e1b-483f-c902-2e9122b13275"
      },
      "source": [
        "model4.fit([X_char_train, X_train], tag_train, validation_data=([X_char_test, X_test], tag_test), batch_size=128, epochs=35, verbose=1)"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.7020 - precision_28: 0.4787 - recall_28: 0.4787 - accuracy: 0.0000e+00 - val_loss: 0.6926 - val_precision_28: 0.5200 - val_recall_28: 0.5200 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6914 - precision_28: 0.5505 - recall_28: 0.5505 - accuracy: 0.0000e+00 - val_loss: 0.6900 - val_precision_28: 0.5500 - val_recall_28: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6839 - precision_28: 0.5441 - recall_28: 0.5441 - accuracy: 0.0000e+00 - val_loss: 0.6918 - val_precision_28: 0.5500 - val_recall_28: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6754 - precision_28: 0.5836 - recall_28: 0.5836 - accuracy: 0.0000e+00 - val_loss: 0.6969 - val_precision_28: 0.5400 - val_recall_28: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6773 - precision_28: 0.5800 - recall_28: 0.5800 - accuracy: 0.0000e+00 - val_loss: 0.7010 - val_precision_28: 0.5250 - val_recall_28: 0.5250 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6716 - precision_28: 0.5749 - recall_28: 0.5749 - accuracy: 0.0000e+00 - val_loss: 0.6991 - val_precision_28: 0.4800 - val_recall_28: 0.4800 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/35\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.6622 - precision_28: 0.5712 - recall_28: 0.5712 - accuracy: 0.0000e+00 - val_loss: 0.6988 - val_precision_28: 0.5000 - val_recall_28: 0.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6545 - precision_28: 0.5988 - recall_28: 0.5988 - accuracy: 0.0000e+00 - val_loss: 0.7038 - val_precision_28: 0.5150 - val_recall_28: 0.5150 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/35\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.6565 - precision_28: 0.6093 - recall_28: 0.6093 - accuracy: 0.0000e+00 - val_loss: 0.7137 - val_precision_28: 0.5100 - val_recall_28: 0.5100 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6545 - precision_28: 0.6020 - recall_28: 0.6020 - accuracy: 0.0000e+00 - val_loss: 0.7150 - val_precision_28: 0.4650 - val_recall_28: 0.4650 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6377 - precision_28: 0.6477 - recall_28: 0.6477 - accuracy: 0.0000e+00 - val_loss: 0.7140 - val_precision_28: 0.5250 - val_recall_28: 0.5250 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.6305 - precision_28: 0.6373 - recall_28: 0.6373 - accuracy: 0.0000e+00 - val_loss: 0.7221 - val_precision_28: 0.5150 - val_recall_28: 0.5150 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.6321 - precision_28: 0.6292 - recall_28: 0.6292 - accuracy: 0.0000e+00 - val_loss: 0.7357 - val_precision_28: 0.5650 - val_recall_28: 0.5650 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.6218 - precision_28: 0.6334 - recall_28: 0.6334 - accuracy: 0.0000e+00 - val_loss: 0.7326 - val_precision_28: 0.5300 - val_recall_28: 0.5300 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.6004 - precision_28: 0.6738 - recall_28: 0.6738 - accuracy: 0.0000e+00 - val_loss: 0.7380 - val_precision_28: 0.5350 - val_recall_28: 0.5350 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.6019 - precision_28: 0.6736 - recall_28: 0.6736 - accuracy: 0.0000e+00 - val_loss: 0.7442 - val_precision_28: 0.5250 - val_recall_28: 0.5250 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.5934 - precision_28: 0.6817 - recall_28: 0.6817 - accuracy: 0.0000e+00 - val_loss: 0.7660 - val_precision_28: 0.5250 - val_recall_28: 0.5250 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.5748 - precision_28: 0.7177 - recall_28: 0.7177 - accuracy: 0.0000e+00 - val_loss: 0.7737 - val_precision_28: 0.5000 - val_recall_28: 0.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5690 - precision_28: 0.6985 - recall_28: 0.6985 - accuracy: 0.0000e+00 - val_loss: 0.7641 - val_precision_28: 0.5100 - val_recall_28: 0.5100 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.5687 - precision_28: 0.6827 - recall_28: 0.6827 - accuracy: 0.0000e+00 - val_loss: 0.7729 - val_precision_28: 0.5150 - val_recall_28: 0.5150 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5472 - precision_28: 0.7252 - recall_28: 0.7252 - accuracy: 0.0000e+00 - val_loss: 0.7884 - val_precision_28: 0.5450 - val_recall_28: 0.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5240 - precision_28: 0.7369 - recall_28: 0.7369 - accuracy: 0.0000e+00 - val_loss: 0.7865 - val_precision_28: 0.5400 - val_recall_28: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5325 - precision_28: 0.7246 - recall_28: 0.7246 - accuracy: 0.0000e+00 - val_loss: 0.7999 - val_precision_28: 0.5400 - val_recall_28: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.5099 - precision_28: 0.7467 - recall_28: 0.7467 - accuracy: 0.0000e+00 - val_loss: 0.8058 - val_precision_28: 0.5500 - val_recall_28: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4854 - precision_28: 0.7717 - recall_28: 0.7717 - accuracy: 0.0000e+00 - val_loss: 0.8450 - val_precision_28: 0.5450 - val_recall_28: 0.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4688 - precision_28: 0.7700 - recall_28: 0.7700 - accuracy: 0.0000e+00 - val_loss: 0.8546 - val_precision_28: 0.5450 - val_recall_28: 0.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4517 - precision_28: 0.7889 - recall_28: 0.7889 - accuracy: 0.0000e+00 - val_loss: 0.8742 - val_precision_28: 0.5650 - val_recall_28: 0.5650 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4161 - precision_28: 0.8127 - recall_28: 0.8127 - accuracy: 0.0000e+00 - val_loss: 0.8719 - val_precision_28: 0.5500 - val_recall_28: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4323 - precision_28: 0.8196 - recall_28: 0.8196 - accuracy: 0.0000e+00 - val_loss: 0.8932 - val_precision_28: 0.5700 - val_recall_28: 0.5700 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.4258 - precision_28: 0.8102 - recall_28: 0.8102 - accuracy: 0.0000e+00 - val_loss: 0.9179 - val_precision_28: 0.5400 - val_recall_28: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/35\n",
            "7/7 [==============================] - 36s 5s/step - loss: 0.3963 - precision_28: 0.8185 - recall_28: 0.8185 - accuracy: 0.0000e+00 - val_loss: 0.9261 - val_precision_28: 0.5550 - val_recall_28: 0.5550 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.3955 - precision_28: 0.8292 - recall_28: 0.8292 - accuracy: 0.0000e+00 - val_loss: 0.9431 - val_precision_28: 0.5450 - val_recall_28: 0.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.3890 - precision_28: 0.8392 - recall_28: 0.8392 - accuracy: 0.0000e+00 - val_loss: 0.9337 - val_precision_28: 0.5500 - val_recall_28: 0.5500 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.3639 - precision_28: 0.8361 - recall_28: 0.8361 - accuracy: 0.0000e+00 - val_loss: 0.9979 - val_precision_28: 0.5400 - val_recall_28: 0.5400 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/35\n",
            "7/7 [==============================] - 37s 5s/step - loss: 0.3766 - precision_28: 0.8311 - recall_28: 0.8311 - accuracy: 0.0000e+00 - val_loss: 1.0179 - val_precision_28: 0.5550 - val_recall_28: 0.5550 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f002fa518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6JPbcvA7rUq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}